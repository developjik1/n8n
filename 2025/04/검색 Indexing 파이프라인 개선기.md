# 🎯 검색 Indexing 파이프라인 개선기

> 🕒 **발행일:** Tue, 15 Apr 2025 06:14:54 GMT  
> 🔗 **원본 링크:** [👉 바로 가기](https://medium.com/daangn/%EA%B2%80%EC%83%89-indexing-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B0%9C%EC%84%A0%EA%B8%B0-c01c64292831?source=rss----4505f82a2dbd---4)

---

## 📌 **핵심 요약**  
📖 안녕하세요! 검색플랫폼팀의 Backend Engineer 하이(Hy)에요.

당근에는 중고거래, 동네생활, 동네업체, 채팅 등 다양한 서비스가 있는데요. 검색플랫폼팀은 검색 서비스를 안정적으로 지원하는 플랫폼을 만들며, 다양한 서비스의 검색을 지원하고 있어요. 이를 위해서는 가장 먼저 각 서비스들의 데이터가 필요한데요. 이번 글에서는 각 서비스의 데이터를 검색 엔진에 전달하는 색인 파이프라인을 운영하면서, 어떤 문제가 있었고 어떻게 해결했는지 이야기하려고 해요.

색인 파이프라인은 1) 실시간성을 보장하기 위한 Online 색인과 2) 사전 변경, 데이터 보정을 위해 하루에 한 번 전체 색인을 하는 Offline 색인을 해요. 이 두 가지를 진행할 때, 기존 파이프라인은 아래와 같은 문제점이 있었어요.

#### 생산성

데이터를 가져오고 색인하는 로직의 패턴은 대부분 동일하지만, 서비스마다 로직이 따로 존재해서 관리 포인트가 많아져요.

#### 의존성

당근의 서비스 DB에 직접적으로 붙어서 데이터를 가져오기 때문에, 각 서비스 DB에 강한 의존성을 가지게 됐어요.

#### 비용

하루에 한 번 OnlineDB의 내용을 전체 Full Scan해야 하기 때문에 색인 파이프라인의 DB의 사이즈가 커야 했어요. 또한 서비스팀에서도 저희를 위한 ReplicaDB를 만들어주어야 해요.

#### 가시성

어떤 필드가 어떻게 색인이 되는지, 필터링 로직 등 색인 로직이 어떻게 구성됐는지 등을 파악하려면, 늘 코드를 전부 일일이 확인해야 했어요.

![](https://cdn-images-1.medium.com/max/1024/1*SRARdWW1QM5Ryfk4aQ3I2w.png)

**이전 색인 파이프라인에서 개발해야 하는 부분**

**위의 4가지 문제를 해결하기 위해 다음과 같은 목표를 세웠어요.**

1. 설정 기반의 인터페이스로 자동화하여, 누구나 기여할 수 있는 생산성이 높은 시스템을 만들어요.
2. 외부 서비스 DB에 대한 의존성을 낮춰서, 상태가 변경되어도 안전한 색인 파이프라인을 만들어요.
3. 하루에 한 번 풀색인(Full Indexing)의 부담을 낮추고 비용을 줄여요.
4. 이벤트가 쏟아져도 안전한 고가용성의 시스템을 만들어요.

#### 1) 설정 기반의 인터페이스로 자동화하여, 누구나 기여할 수 있는 생산성이 높은 시스템을 만들어요.

위의 목표를 달성하기 위해서는 동작을 명시하는 설정 Interface가 잘 정의되어야 해요. 또한 아무리 자동화가 목적이라도 안전한 시스템을 갖추기 위해선, 먼저 안전한 스키마를 설계해야 해요. 그래서 아래와 같은 원칙을 세웠어요.

* 해당 인터페이스에 명시된 동작만 이루어져야 하며, 이외에 다른 동작을 하는 마술은 부리지 않아야 함
* 모든 데이터는 스키마를 가지고 안전하게 처리할 수 있도록 해야 함
* 모든 in/out 사이에는 비즈니스로직을 자유롭게 넣을 수 있어야 함
* 사용자가 몰라도 되는 core 로직은 데이터 처리 외에는 하지 않아야 함

먼저 동작을 명시하는 Interface를 정의하기 위해 비교적 접근성이 쉬운 yaml을 사용하였어요. 아래는 데이터를 어떻게 가져오고, 적재하고, 관리할지를 보여주는 Datastore의 Interface 예시예요.

version: 1  
name: {서비스이름}_datastore  
storage: datastore  
sources:  
  - table: {테이블명}_v2  
    comment: "{설명 주석}"  
    country: ### 사용되는 나라만 넣어주세요.  
    primary_key: {primary_key_field}  
    schema: {DB schema 경로} ### dbschema/{테이블명}.yaml로 만들어주세요 schema의 type은 MySQL 타입기준으로 만들어주시면 됩니다.  
    scan:  
      type: time  
      target_field: {스키마의 변경시간 field이름} ### 데이터 비교 및 최신데이터를 구별할 필드이름을 넣어주세요 예시) updated_at  
      ttl_interval_ms: {ttl ms}  
      ### 예시) 온라인 디비에 적재할 TTL 시간을 넣어주세요 예시) 43200000, -1로 하면 영원히 가지고 있게 됩니다.  
    subscribe_message:  
      - topic: {kafka_topic} ### 인덱서에서 읽어 들일 카프카 topic을 넣어주세요 예시) event.search.region  
        transform: {transform name}  
        ### 해당 메시지를 처리할 transform의 이름을 넣어주세요 검색팀이 아닌 경우 직접 transform로직을 작성해 주셔도 좋고, 비워두시고 검색 플랫폼팀에게 요청을 주시면 검색 팀에서 만들어드립니다.  
    publish_message:  
      - topic: services.searchindexer.internal.job_state_change_v1  
        ## bigquery cdc 로그에 적재할 토픽에 true를 넣어줍니다.  
        cdc: true  
    auto_indexing:  
      - option: simple  
        generate_policy: always  
        partition_page_size: 100000  
        ## 데이터 스토어 형태에서 검색엔진에 데이터를 삭제할 조건을 넣습니다.  
        active_conditions:  
          - destroyed_at is null  
....          
    deployments: ### env prod / alpha 배포 설정을 넣어주세요. 지정된 환경변수만 배포가 되어요.  
      - env: alpha  
        slack_alarm_channel: '#슬랙채널'  
    transform_parameter:  
      - env: alpha  
        pipeline:  
          kr:  
            configs:  
              - name: flea_market_image_vector_v1  
                tensorflow_serving_config: tensorflowserving/alpha/kr/flea_market_vector_v1.yaml       offline:  
    executors:  
      - env: alpha ### env prod / alpha  
        back_fill: ### backfill sql 경로를 넣어주세요  
          sql:  
            all: backfill/regions.sql  
        resources: ### 리소스 default는 memory: 512Mi cpu: 500m이에요.  
          kr:  
           limits:  
             memory: 512Mi  
             cpu: 500m  
           requests:  
             memory: 512Mi  
             cpu: 500m

위의 interface를 작성하고 명령어를 치면 시스템에서 코드를 생성해요. **“모든 데이터는 스키마를 가져서 안전하게 처리해야 함”**이라는 원칙을 보장하기 위해 “코드 생성 방식”을 선택했어요. 또한 Online 이벤트와 Offline 데이터를 똑같은 형태로 만들어야 하기 때문에, 시스템에서 Schema를 코드로 만드는 것이 가장 안전하다고 판단했어요.

아래는 위의 Interface의 Schema를 읽고 생성한 코드 예시예요.

// Code generated by indexer/message. DO NOT EDIT.  
// versions: v1  
// source: message/schema/.../articles_datastore.yaml  
// 중고거래 article MySQL 테이블 모델  
  
package articlesdatastore  
import (  
   "github.com/daangn/search-indexer/message/entity"  
   "github.com/daangn/search-indexer/message/entity/utils"  
   "time"  
)  
var _ entity.IndexerMySQLMessage = &ArticlesV2{}  
type FleaMarket struct {  
 ID                      int64      `db:"id" json:"id" bigquery:"id" structs:"id"`  
 Title                   *string    `db:"title" json:"title" bigquery:"title" structs:"title"`  
 Content                 *string    `db:"content" json:"content" bigquery:"content" structs:"content"`  
.....

유연한 플랫폼을 만들려면, 엔지니어가 모든 input 데이터를 자유롭게 변환할 수 있어야 해요. 이를 위해 Interface 중간에 엔지니어가 직접 코드를 삽입할 수 있는 Transform 단계를 만들어뒀어요. 외부에서 받아온 메시지는 Transform의 로직을 거쳐 변환되고, 그 후 OnlineStorage와 상태 변경 이벤트를 통해 OfflineStorage에 적재돼요. Transform을 구현하는 구체적인 방식은 아래와 같아요.

type DataLoaderMessageTransform interface {  
    // GetName transform 이름 : schema yaml transform 필드에 들어갈 이름  
    GetName() string  
  
    // Transform 변환 로직이 들어갈 곳 return 값이 DataStore에 적재됨  
    // kafka message를 파싱해 다시 DB에서 값을 가져오거나  
    // message안에 데이터가 있다면 변환해서 생성된 MySQL Schema모델에 채워서 리턴해준다.  
    MessageTransform(ctx context.Context,   
                     parameter entity.TransformParameter,  
                     msg *kafka.Message) (entity.IndexerMySQLMessage, error)  
  
    // CustomClearSQL Custom 하여 지우는 로직을 넣는 SQL  
    // custom 이 필요 없이 나 자신을 Clear 하는 것이라면 retrun "" 하면 된다  
    // 릴레이션되어 1:N관계 일 때 1에 릴레이션되어 커스텀 SQL을 넣고 싶을 때 사용하면 된다.  
    CustomClearSQL() string  
}

SearchEngine에 적재하는 Indexing Inteface도 이와 비슷한 형태로 만들 수 있어요. 추가적으로, 코드를 생성시키면 Airflow에 Offline 색인 파이프라인이 자동으로 생기도록 하였어요.

![](https://cdn-images-1.medium.com/max/1024/1*juJHipwXCiF8xBUrBEwDpw.png)

![](https://cdn-images-1.medium.com/max/1024/1*xB642YdttfLuZcGm55Ihzw.png)

자동으로 생성된 Airflow Dag

#### 2) 외부 서비스 DB와 의존성을 낮춰서, 안전한 색인 파이프라인을 만들어요

대부분 서비스의 DB는 MySQL, MongoDB 같은 OnlineDB 일 거예요. OnlineDB는 실시간으로 변할 수 있는 상태이기 때문에, 직접 외부 서비스의 OnlineDB를 바라보는 것은 장애 포인트가 될 수 있어요. 또 풀색인 시에 모든 데이터를 읽어오기 위한 비용도 크고 유지하기가 어려워요. 이를 해결하고자 저희는 Offline Storage를 사용하기로 결정하였어요.

당근은 OfflineStorage로 BigQuery를 사용하고 있고, 모든 서비스의 데이터가 BigQuery에 잘 적재되어 있는데요. 이는 서비스에서 직접적으로 사용되는 데이터이기 때문에 DB의 신뢰성과 성능, 그리고 비용을 잘 관리해야 했어요.

먼저, 위의 datastore inteface에 명시된 backfill로 가져온 데이터로 빈 데이터를 채워주었어요. 그리고 WAL(Write-Ahead Log)과 같은 형태의 상태 변경 메시지를 발행하여, 데이터를 OfflineStorage에 적재했어요. 이때 적재된 데이터를 가장 우선순위가 높은 데이터로 활용하였어요.

> _“상태 변경 이벤트”는 특정 요인에서 순서, 시간 등 이 잘못될 수 있기 때문에 이벤트 메시지에는 ID만 발행해요. 그다음 CDCStreaming 애플리케이션에서 ID를 기준으로 데이터를 조회한 후, Schema에 맞춘 변환 로직을 거쳐서 OfflineStorage에 저장해요._

프로세스는 다음과 같아요.

* 먼저 외부 데이터를 Backfill하여 빈데이터를 채워줘요.

![](https://cdn-images-1.medium.com/max/1024/1*HAdsVSlKSqUt-SusfKC5bg.png)

* Scan 하는 필드를 기준으로 Streaming 데이터를 비교하여 더 큰 값을 우선순위로 정해요. 그 후 ID 기준의 유니크한 Row를 가지는 형태로 머지하고, Offline 색인 테이블에 Overwrite 해요.

![](https://cdn-images-1.medium.com/max/1024/1*i4j0MxrKSi3R-vRfPXFtNQ.png)

* 위의 프로세스로 전체 데이터를 채워주면 Backfill시에 잘못된 데이터가 들어와도, 저희의 데이터로 overwrite하기 때문에 안전한 데이터 테이블을 만들어 색인할 수 있었어요.
* 마지막으로 OfflineStorage의 최신 데이터 이후의 데이터도 함께 처리해줘야 하는데요. 해당 데이터는 색인 파이프라인에서 사용하는 OnlineDB에서 가져와 실시간성까지 보장할 수 있었어요.

![](https://cdn-images-1.medium.com/max/1024/1*yzjKo8UjpZ-Th9z5bENvyQ.png)

#### 3) 하루에 한 번 풀색인의 부담을 낮추고 비용을 줄여요.

하루에 한 번 전체 데이터를 가져와 색인하는 과정에서 **“어떻게 OffineStorage에서 적은 비용으로 빠르게 데이터를 가져올 수 있을까?”** 하는 고민을 가지게 됐어요. BigQuery 같은 OfflineStorage는 파일 시스템이기 때문에 특정한 범위를 가져오는 SQL을 작성하더라도 FullScan을 발생시켜요. 해당 문제를 해결하기 위해 색인 파이프라인에서 데이터를 읽기 전, 데이터를 파티셔닝하고 복제 테이블을 만드는 작업을 하였어요.

* Offline 색인 시작 전 data table에서 partition 룰을 통하여 partition을 나눈 임시 테이블을 생성해요.

![](https://cdn-images-1.medium.com/max/1024/1*9s2xtKIZvFotROKqOGL7gg.png)

![](https://cdn-images-1.medium.com/max/1024/1*pg0SkpOqZZHz0yT07Xu_ZQ.png)

**실제 airflow log**

* 색인 파이프라인에서 각 분산된 Processor별로 할당된 파티션을 읽고, Processor 내부의 Task들이 데이터를 검색엔진에 색인해요.

![](https://cdn-images-1.medium.com/max/1024/1*VvovzE1EmkHszFuAsuKHnA.png)

위와 같이 작업을 하고 하니 하루에 수억 건의 데이터를 색인하는데, 1\~2시간 정도 끝나는 성능을 보였어요. 게다가 1\~2만 원 정도의 비용밖에 들지 않았고요.

실제로 Spark 같은 오픈소스가 이 문제를 어떻게 해결하는지 들여다보니 위에서 작업한 형태와 크게 다르지 않다는 것을 확인했어요. 이를 통해 현재 접근 방식에 대한 신뢰와 확신을 좀 더 가질 수 있었어요.

#### 4) 이벤트가 쏟아져도 안전한 고가용 시스템을 만들어요.

색인 파이프라인을 오픈된 형태로 유지하려면, 무수히 많은 카프카 이벤트에도 안전한 시스템을 만들어야 해요. 실제로 내부 서비스 중 어떤 서비스는 초당 수천 건의 이벤트를 발행해요. 이러한 상황에서 비용을 최소화하고 성능을 극대화할 방법을 찾아야 했어요.

대부분의 서비스들은 초당 많아야 100건 이내의 이벤트가 발생하기 때문에, 각 이벤트를 OnlineDB에 적재해도 큰 문제가 없어요. 다만, 초당 수천 건 이상의 데이터를 밀어 넣는 서비스의 경우, 혹은 해당 파이프라인에서 embedding vector를 생성하거나 모델 inference를 하는 Latency가 긴 서비스의 경우, KafkaLag가 생기거나 DB의 부하가 급격히 증가해 다른 서비스에도 영향을 줄 수 있어요.

해당 문제를 해결하기 위해 Streaming Tumbling TimeWindow을 만들어 Streaming Batch 처리를 가능하게 하였어요. 검색엔진에 적재할 때도 동일하게 Streaming Batch 처리를 해요.

Indexer Pipeline의 TimeWindow 동작 방식은 Streaming OpenSource들을 모방하여 Local 머신마다 StateStore를 가지고 처리할 수 있도록 구현했어요.

streams := kafka.NewStream(topic, config.KafkaConsumer).  
		WindowTime(windowTime).  
		Transform(func(ctx context.Context, msg *kafka2.Message) (interface{}, interface{}, error) {  
				return msg.key, msg.Value, nil  
			}, consumeFailProcess).  
		Process(func(ctx context.Context, window *TimeWindow) error {  
		...  
			return nil  
		}, consumeFailProcess)

아래와 같이 설정에 time window 기간을 명시하고, 아래 “flea\_market\_vector\_v1”라는 이름으로 DataLoaderBatchStreamingTransform를 구현했어요. 이 로직을 transform에 넣어주면 TumblingWindow 형태로 데이터를 모아서 batch 처리를 할 수 있어요.

subscribe_message:  
      - topic: indexing.fleamarket.flea_market_article.v1  
        transform: flea_market_vector_v1  
        window_time_milliseconds: 2000

type DataLoaderBatchStreamingTransform interface {  
    // GetName transform 이름 : schema yaml transform 필드에 들어갈 이름  
    GetName() string  
    // Preprocess batch transform전 단일 문서에 대해 전처리를 수행합니다.  
    Preprocess(ctx context.Context,  
               parameter entity.TransformParameter,  
               msg *kafka.Message) (entity.IndexerMessage, error)  
    // BatchTransform bulk로 변환 로직이 들어갈 곳 return 값이 DataStore에 적재됨  
    BatchTransform(ctx context.Context,  
                   parameter entity.TransformParameter,  
                   data []entity.IndexerMessage) ([]entity.IndexerMySQLMessage, error)  
}

해당 작업을 통해 1.5core의 pod 8대 만으로도 초당 수만 건의 이벤트를 무리 없이 처리할 수 있었어요.

이외에도 최근까지 Transform을 자동으로 생성해 주는 옵션, Vector Emebdding, LLM, Model Inference, 수많은 PR 테스트와 모니터링 등 검색 서비스를 안정적으로 지원하기 위해 다양한 작업을 지속하고 있어요.

![](https://cdn-images-1.medium.com/max/1024/1*0w3ElC3X2PvwGmFCjBEzDg.png)

Model Inference 등 기능이 추가되고 있는 Indexer pipeline

#### 마무리

지금까지 당근의 검색플랫폼팀에서 색인 파이프라인의 안정성과 생산성을 높이기 위해 고민하고 개선했던 과정들을 소개했어요.

서비스가 성장할수록 더 많은 데이터를 효율적으로 처리할 수 있는 구조가 필요해지고, 동시에 서비스 간 의존성을 낮추고 가시성을 높여야 하는데요. 앞으로도 저희 검색플랫폼팀은 더욱 편리하고 신뢰할 수 있는 검색 환경을 사용자와 개발자 모두에게 제공하기 위해 다양한 시도를 계속할 예정이에요. 당근의 검색 플랫폼이 어떤 모습으로 발전해 나갈지 많은 관심 부탁드리며, 함께 고민하고 성장할 멋진 동료들을 언제나 환영합니다!

긴 글 읽어주셔서 감사합니다. 😊

검색인프라 채용: <https://about.daangn.com/jobs/5688517003/>

![](https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=c01c64292831)

---

[검색 Indexing 파이프라인 개선기](https://medium.com/daangn/%EA%B2%80%EC%83%89-indexing-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B0%9C%EC%84%A0%EA%B8%B0-c01c64292831) was originally published in [당근 테크 블로그](https://medium.com/daangn) on Medium, where people are continuing the conversation by highlighting and responding to this story.

---

## 📋 **추가 정보**  
🔹 **게시 날짜:** Tue, 15 Apr 2025 06:14:54 GMT  
🔹 **출처:** [원본 링크](https://medium.com/daangn/%EA%B2%80%EC%83%89-indexing-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EA%B0%9C%EC%84%A0%EA%B8%B0-c01c64292831?source=rss----4505f82a2dbd---4)  
🔹 **관련 태그:** #RSS #자동화 #n8n  

---

> ✨ _이 문서는 자동 생성되었습니다. 🚀 Powered by n8n_
